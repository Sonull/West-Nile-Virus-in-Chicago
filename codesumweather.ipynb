{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Station 1: CHICAGO O'HARE INTERNATIONAL AIRPORT Lat: 41.995 Lon: -87.933 Elev: 662 ft. above sea level\n",
    "#Station 2: CHICAGO MIDWAY INTL ARPT Lat: 41.786 Lon: -87.752 Elev: 612 ft. above sea level\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Station', 'Date', 'Tmax', 'Tmin', 'Tavg', 'Depart', 'DewPoint',\n",
       "       'WetBulb', 'Heat', 'Cool', 'Sunrise', 'Sunset', 'CodeSum',\n",
       "       'PrecipTotal', 'StnPressure', 'SeaLevel', 'ResultSpeed', 'ResultDir',\n",
       "       'AvgSpeed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load file \"weather.csv\"\n",
    "df = pd.read_csv('/Users/jenniferwu/Documents/kaggle-competition1/datasets/weather.csv')\n",
    "\n",
    "# Drop columns:\"Depth\", \"Water1\", \"Snowfall\"\n",
    "df = df.drop(columns = ['Depth','Water1','SnowFall'])\n",
    "\n",
    "\n",
    "df.head()\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Lat and Lon Columns ############\n",
    "\n",
    "# Add columns to show where the station is (lat,lon) and its reading measures\n",
    "df['WeatherLat'] = np.where(df['Station']==1, 41.995, 41.786)\n",
    "df['WeatherLon'] = np.where(df['Station']==1, -87.933, -87.752)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move newly added columns from the end 2 spots to after the Station column\n",
    "my_column = df.pop('WeatherLat')\n",
    "my_column1 = df.pop('WeatherLon')\n",
    "df.insert(1, my_column.name, my_column)\n",
    "df.insert(2, my_column1.name, my_column1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Tavg Column ############\n",
    "\n",
    "# Replace M in Tavg with Tmax-Tmin / 2 + Tmin\n",
    "df['Tavg'].replace(to_replace='M',value = (df['Tmax']-df['Tmin'])/2 + df['Tmin'], inplace=True)\n",
    "\n",
    "# Change Tavg type from object to int\n",
    "df[[\"Tavg\"]] = df[[\"Tavg\"]].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def convert_to_datetime(time_str):\n",
    "    try:\n",
    "        return datetime.datetime.strptime(time_str,\"%H%M\").time()\n",
    "    except Exception as e:\n",
    "        print(time_str)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Station  WeatherLat  WeatherLon        Date  Tmax  Tmin  Tavg Depart  \\\n",
      "0        1      41.995     -87.933  2007-05-01    83    50    67     14   \n",
      "1        2      41.786     -87.752  2007-05-01    84    52    68      M   \n",
      "2        1      41.995     -87.933  2007-05-02    59    42    51     -3   \n",
      "3        2      41.786     -87.752  2007-05-02    60    43    52      M   \n",
      "4        1      41.995     -87.933  2007-05-03    66    46    56      2   \n",
      "\n",
      "   DewPoint WetBulb  ... CodeSum PrecipTotal StnPressure SeaLevel ResultSpeed  \\\n",
      "0        51      56  ...                0.00       29.10    29.82         1.7   \n",
      "1        51      57  ...                0.00       29.18    29.82         2.7   \n",
      "2        42      47  ...      BR        0.00       29.38    30.09        13.0   \n",
      "3        42      47  ...   BR HZ        0.00       29.44    30.08        13.3   \n",
      "4        40      48  ...                0.00       29.39    30.12        11.7   \n",
      "\n",
      "  ResultDir AvgSpeed sunrise_new  sunset_new  sunset_new1  \n",
      "0        27      9.2    04:48:00        1849     18:49:00  \n",
      "1        25      9.6    00:00:00        0000     00:00:00  \n",
      "2         4     13.4    04:47:00        1850     18:50:00  \n",
      "3         2     13.4    00:00:00        0000     00:00:00  \n",
      "4         7     11.9    04:46:00        1851     18:51:00  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Sunrise\n",
    "df['sunrise_new']=df['Sunrise'].replace('-', '0000').apply(convert_to_datetime)\n",
    "#df['sunrise_new1']=df['sunrise_new'].apply(convert_to_datetime)\n",
    "\n",
    "#Sunset\n",
    "\n",
    "df['sunset_new']=df['Sunset'].replace('-', '0000')\n",
    "df['sunset_new']=df['sunset_new'].replace('1660', '1700')\n",
    "df['sunset_new']=df['sunset_new'].replace('1760', '1800')\n",
    "df['sunset_new']=df['sunset_new'].replace('1860', '1900')\n",
    "\n",
    "df['sunset_new1']=df['sunset_new'].apply(convert_to_datetime)\n",
    "\n",
    "\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate into two dataframes by station 1 and 2\n",
    "is_station1 =  df['Station']==1\n",
    "dfStation1 = df[is_station1]\n",
    "is_station2 =  df['Station']==2\n",
    "dfStation2 = df[is_station2]\n",
    "\n",
    "# Join both dataframes next to each other on the Date and add respective station label to end\n",
    "a = dfStation1.join(dfStation2.set_index('Date'), on='Date', lsuffix = '_Station1', rsuffix='_Station2')\n",
    "\n",
    "# Reset the Index of the whole dataframe\n",
    "a.reset_index(drop = True,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Station_Station1  WeatherLat_Station1  WeatherLon_Station1        Date  \\\n",
      "0                 1               41.995              -87.933  2007-05-01   \n",
      "1                 1               41.995              -87.933  2007-05-02   \n",
      "2                 1               41.995              -87.933  2007-05-03   \n",
      "3                 1               41.995              -87.933  2007-05-04   \n",
      "4                 1               41.995              -87.933  2007-05-05   \n",
      "\n",
      "   Tmax_Station1  Tmin_Station1  Tavg_Station1 Depart_Station1  \\\n",
      "0             83             50             67              14   \n",
      "1             59             42             51              -3   \n",
      "2             66             46             56               2   \n",
      "3             66             49             58               4   \n",
      "4             66             53             60               5   \n",
      "\n",
      "   DewPoint_Station1 WetBulb_Station1  ... CodeSum_Station2  \\\n",
      "0                 51               56  ...                    \n",
      "1                 42               47  ...            BR HZ   \n",
      "2                 40               48  ...               HZ   \n",
      "3                 41               50  ...                    \n",
      "4                 38               49  ...                    \n",
      "\n",
      "  PrecipTotal_Station2 StnPressure_Station2 SeaLevel_Station2  \\\n",
      "0                 0.00                29.18             29.82   \n",
      "1                 0.00                29.44             30.08   \n",
      "2                 0.00                29.46             30.12   \n",
      "3                 0.00                29.36             30.04   \n",
      "4                    T                29.46             30.09   \n",
      "\n",
      "  ResultSpeed_Station2 ResultDir_Station2 AvgSpeed_Station2  \\\n",
      "0                  2.7                 25               9.6   \n",
      "1                 13.3                  2              13.4   \n",
      "2                 12.9                  6              13.2   \n",
      "3                 10.1                  7              10.4   \n",
      "4                 11.2                  7              11.5   \n",
      "\n",
      "  sunrise_new_Station2  sunset_new_Station2  sunset_new1_Station2  \n",
      "0             00:00:00                 0000              00:00:00  \n",
      "1             00:00:00                 0000              00:00:00  \n",
      "2             00:00:00                 0000              00:00:00  \n",
      "3             00:00:00                 0000              00:00:00  \n",
      "4             00:00:00                 0000              00:00:00  \n",
      "\n",
      "[5 rows x 47 columns]\n"
     ]
    }
   ],
   "source": [
    "print(a.head())\n",
    "############ Preciptotal Column ############\n",
    "\n",
    "# Replace M value with value from Station on same date that actually has a value\n",
    "a['PrecipTotal_Station1'].replace(to_replace='M',value = a['PrecipTotal_Station2'], inplace=True)\n",
    "a['PrecipTotal_Station2'].replace(to_replace='M',value = a['PrecipTotal_Station1'], inplace=True)\n",
    "\n",
    "# Replace T value with value from Station on same date that actually has a value\n",
    "a['PrecipTotal_Station1'].replace(to_replace='  T',value = a['PrecipTotal_Station2'], inplace=True)\n",
    "a['PrecipTotal_Station2'].replace(to_replace='  T',value = a['PrecipTotal_Station1'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Now that the only T's remaining are where its in both Station1 and 2, replace with 0\n",
    "a['PrecipTotal_Station1'].replace(to_replace='  T',value = 0.00, inplace=True)\n",
    "a['PrecipTotal_Station2'].replace(to_replace='  T',value = 0.00, inplace=True)\n",
    "\n",
    "# Change PrecipTotal types to floats from objects\n",
    "a[[\"PrecipTotal_Station1\"]] = a[[\"PrecipTotal_Station1\"]].astype(float)\n",
    "a[[\"PrecipTotal_Station2\"]] = a[[\"PrecipTotal_Station2\"]].astype(float)\n",
    "\n",
    "############ STNpressure Column ############\n",
    "\n",
    "# Replace M value with value from Station on same date that actually has a value\n",
    "a['StnPressure_Station1'].replace(to_replace='M',value = a['StnPressure_Station2'], inplace=True)\n",
    "a['StnPressure_Station2'].replace(to_replace='M',value = a['StnPressure_Station1'], inplace=True)\n",
    "\n",
    "# Find Indexes of spots where both Station 1 and Station 2 have value \"M\" and replace with avg of index above and below\n",
    "Index_label1 = a[a['StnPressure_Station1']=='M'].index.tolist()\n",
    "for i in Index_label1:\n",
    "    a['StnPressure_Station2'].replace(to_replace='M',value = (float(a.at[i+1,'StnPressure_Station2']) + float(a.at[i-1,'StnPressure_Station2']))/2 , inplace=True)\n",
    "    a['StnPressure_Station1'].replace(to_replace='M', value=(float(a.at[i+1, 'StnPressure_Station1']) + float(a.at[i-1, 'StnPressure_Station1'])) / 2, inplace=True)\n",
    "\n",
    "# Change StnPressure types to floats from objects\n",
    "a[[\"StnPressure_Station1\"]] = a[[\"StnPressure_Station1\"]].astype(float)\n",
    "a[[\"StnPressure_Station2\"]] = a[[\"StnPressure_Station2\"]].astype(float)\n",
    "\n",
    "############ Sealevel Column ############\n",
    "\n",
    "# Replace M value with value from Station on same date that actually has a value\n",
    "a['SeaLevel_Station1'].replace(to_replace='M',value = a['SeaLevel_Station2'], inplace=True)\n",
    "a['SeaLevel_Station2'].replace(to_replace='M',value = a['SeaLevel_Station1'], inplace=True)\n",
    "\n",
    "# Change Sealevel types to floats from objects\n",
    "a[[\"SeaLevel_Station1\"]] = a[[\"SeaLevel_Station1\"]].astype(float)\n",
    "a[[\"SeaLevel_Station2\"]] = a[[\"SeaLevel_Station2\"]].astype(float)\n",
    "\n",
    "############ AvgSpeed Column ############\n",
    "\n",
    "# Replace M value with value from Station on same date that actually has a value\n",
    "a['AvgSpeed_Station1'].replace(to_replace='M',value = a['AvgSpeed_Station2'], inplace=True)\n",
    "a['AvgSpeed_Station2'].replace(to_replace='M',value = a['AvgSpeed_Station1'], inplace=True)\n",
    "\n",
    "# Change AvgSpeed types to floats from objects\n",
    "a[[\"AvgSpeed_Station1\"]] = a[[\"AvgSpeed_Station1\"]].astype(float)\n",
    "a[[\"AvgSpeed_Station2\"]] = a[[\"AvgSpeed_Station2\"]].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['Depart_Station2'] = np.where((a.Depart_Station2 == 'M'),\n",
    "                                            a.Depart_Station1, a.Depart_Station2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['Heat_Station2']:\n",
    "    a[col] = a[col].fillna(a['Heat_Station1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['Heat_Station2'] = np.where((a.Heat_Station2 == 'M'),\n",
    "                                            a.Heat_Station1, a.Heat_Station2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['WetBulb_Station1']= pd.to_numeric(a['WetBulb_Station1'], errors = 'coerce')\n",
    "# calculate mean of WetBulb_Station1 = WetBulb_Station1_mean\n",
    "WetBulb_Station1_mean = a['WetBulb_Station1'].mean(skipna = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace the missing value of WetBulb_Station1 with the WetBulb_Station1_mean\n",
    "a['WetBulb_Station1'] = a.WetBulb_Station1.fillna(WetBulb_Station1_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the type of Wetbulb_Station2 Column to numeric \n",
    "a['WetBulb_Station2']= pd.to_numeric(a['WetBulb_Station2'], errors = 'coerce')\n",
    "# calculate mean of WetBulb_Station2\n",
    "WetBulb_Station2_mean = a['WetBulb_Station2'].mean(skipna = True)\n",
    "a['WetBulb_Station2'] = a.WetBulb_Station2.fillna(WetBulb_Station2_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_celcius(x):\n",
    "    c = ((x-32)/9)*5\n",
    "    return(c)\n",
    "\n",
    "def rel_hum(dry,wet,press=0.6687451584):\n",
    "    e = float(math.e)\n",
    "    ed = 6.112*(e**((17.502*dry)/(240.97+dry)))\n",
    "    ew = 6.112*(e**((17.502*wet)/(240.97+wet)))\n",
    "    result = (ew-press*(1+.00115*wet)*(dry-wet))/ed*100\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['Tavg_Station1']= pd.to_numeric(a['Tavg_Station1'], errors = 'coerce')\n",
    "a['Tavg_Station2']= pd.to_numeric(a['Tavg_Station2'], errors = 'coerce')\n",
    "#final_station['StnPressure_Station1']= pd.to_numeric(final_station['StnPressure_Station1'], errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "a['WetBulb_Station1_c']=a.WetBulb_Station1.apply(to_celcius)\n",
    "a['Tavg_Station1_c']=a.Tavg_Station1.apply(to_celcius)\n",
    "\n",
    "a['WetBulb_Station2_c']=a.WetBulb_Station2.apply(to_celcius)\n",
    "a['Tavg_Station2_c']=a.Tavg_Station2.apply(to_celcius)\n",
    "\n",
    "a['rel_hum_station1']=rel_hum(a['Tavg_Station1_c'],a['WetBulb_Station1_c'])\n",
    "a['rel_hum_station2']=rel_hum(a['Tavg_Station2_c'],a['WetBulb_Station2_c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing station 2 sunset and sunrise with station 1 values\n",
    "a[[\"sunrise_new_Station2\"]] = a[[\"sunrise_new_Station2\"]].astype(str)\n",
    "a[[\"sunset_new1_Station2\"]] = a[[\"sunset_new1_Station2\"]].astype(str)\n",
    "a['sunrise_new_Station2'].replace(to_replace='00:00:00',value = a['sunrise_new_Station1'], inplace=True)\n",
    "a['sunset_new1_Station2'].replace(to_replace='00:00:00',value = a['sunset_new1_Station1'], inplace=True)\n",
    "\n",
    "#drop sunrise and sunset columns not needed\n",
    "a = a.drop(columns = ['Sunrise_Station1','Sunset_Station1','sunset_new_Station1','sunset_new_Station2'])\n",
    "\n",
    "#rename sunrise and sunset columns \n",
    "a.rename(columns={\"sunrise_new_Station1\":\"Sunrise_Station1\",\"sunset_new1_Station1\":\"Sunset_Station1\",\n",
    "                  \"sunrise_new_Station2\":\"Sunrise_Station2\",\"sunset_new1_Station2\":\"Sunset_Station2\"},inplace = True)    \n",
    "\n",
    "#codeSum\n",
    "a['CodeSum_Station1']=a['CodeSum_Station1'].replace(' ', 'NO EVENT')\n",
    "a['CodeSum_Station2']=a['CodeSum_Station2'].replace(' ', 'NO EVENT')    \n",
    "\n",
    "\n",
    "#cool\n",
    "a['Cool_Station2'] = np.where((a.Cool_Station2 == 'M'),a.Cool_Station1, a.Cool_Station2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "codesum = list()\n",
    "for i in a.CodeSum_Station2:\n",
    "    if i == 'NO EVENT':\n",
    "        v = ['NO EVENT']\n",
    "    else:\n",
    "        v = i.split(' ')  \n",
    "    codesum.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BCFG', 'BR', 'DZ', 'FG', 'FG+', 'FU', 'GR', 'HZ', 'NO EVENT', 'RA', 'SN', 'SQ', 'TS', 'TSRA', 'VCFG', 'VCTS']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = set()\n",
    "for item in codesum:\n",
    "    s.update(item)\n",
    "print(sorted(list(s)))\n",
    "len(list(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "BCFG1 = []\n",
    "BR1 = []\n",
    "DZ1 = []\n",
    "FG1 = [] \n",
    "FGplus_1 = [] \n",
    "FU1 = []\n",
    "GR1 = []\n",
    "HZ1 = []\n",
    "NO_EVENT1 = [] \n",
    "RA1 = []\n",
    "SN1 = [] \n",
    "SQ1 = [] \n",
    "TS1 =[]\n",
    "TSRA1 = []\n",
    "VCFG1 = []\n",
    "VCTS1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(a.CodeSum_Station1)):\n",
    "    if re.findall(ls[0],a.CodeSum_Station1[i]):\n",
    "        BCFG1.append(1)\n",
    "    else:\n",
    "        BCFG1.append(0)\n",
    "        \n",
    "for i in range(len(a.CodeSum_Station1)):\n",
    "    if re.findall(ls[1],a.CodeSum_Station1[i]):\n",
    "        BR1.append(1)\n",
    "    else:\n",
    "        BR1.append(0)\n",
    "        \n",
    "for i in range(len(a.CodeSum_Station1)):\n",
    "    if re.findall(ls[2],a.CodeSum_Station1[i]):\n",
    "        DZ1.append(1)\n",
    "    else:\n",
    "        DZ1.append(0)\n",
    "\n",
    "for i in range(len(a.CodeSum_Station1)):\n",
    "    if re.findall(ls[3],a.CodeSum_Station1[i]):\n",
    "        FG1.append(1)\n",
    "    else:\n",
    "        FG1.append(0)\n",
    "\n",
    "for i in range(len(a.CodeSum_Station1)):\n",
    "    if re.findall(ls[4],a.CodeSum_Station1[i]):\n",
    "        FGplus_1.append(1)\n",
    "    else:\n",
    "        FGplus_1.append(0)        \n",
    "\n",
    "for i in range(len(a.CodeSum_Station1)):\n",
    "    if re.findall(ls[5],a.CodeSum_Station1[i]):\n",
    "        FU1.append(1)\n",
    "    else:\n",
    "        FU1.append(0)  \n",
    "        \n",
    "for i in range(len(a.CodeSum_Station1)):\n",
    "    if re.findall(ls[6],a.CodeSum_Station1[i]):\n",
    "        GR1.append(1)\n",
    "    else:\n",
    "        GR1.append(0)  \n",
    "        \n",
    "for i in range(len(a.CodeSum_Station1)):\n",
    "    if re.findall(ls[7],a.CodeSum_Station1[i]):\n",
    "        HZ1.append(1)\n",
    "    else:\n",
    "        HZ1.append(0)  \n",
    "        \n",
    "for i in range(len(a.CodeSum_Station1)):\n",
    "    if re.findall(ls[8],a.CodeSum_Station1[i]):\n",
    "        NO_EVENT1.append(1)\n",
    "    else:\n",
    "        NO_EVENT1.append(0)  \n",
    "        \n",
    "for i in range(len(a.CodeSum_Station1)):\n",
    "    if re.findall(ls[9],a.CodeSum_Station1[i]):\n",
    "        RA1.append(1)\n",
    "    else:\n",
    "        RA1.append(0)  \n",
    "        \n",
    "for i in range(len(a.CodeSum_Station1)):\n",
    "    if re.findall(ls[10],a.CodeSum_Station1[i]):\n",
    "        SN1.append(1)\n",
    "    else:\n",
    "        SN1.append(0)  \n",
    "        \n",
    "for i in range(len(a.CodeSum_Station1)):\n",
    "    if re.findall(ls[11],a.CodeSum_Station1[i]):\n",
    "        SQ1.append(1)\n",
    "    else:\n",
    "        SQ1.append(0)  \n",
    "        \n",
    "for i in range(len(a.CodeSum_Station1)):\n",
    "    if re.findall(ls[12],a.CodeSum_Station1[i]):\n",
    "        TS1.append(1)\n",
    "    else:\n",
    "        TS1.append(0)  \n",
    "        \n",
    "for i in range(len(a.CodeSum_Station1)):\n",
    "    if re.findall(ls[13],a.CodeSum_Station1[i]):\n",
    "        TSRA1.append(1)\n",
    "    else:\n",
    "        TSRA1.append(0)  \n",
    "        \n",
    "for i in range(len(a.CodeSum_Station1)):\n",
    "    if re.findall(ls[14],a.CodeSum_Station1[i]):\n",
    "        VCFG1.append(1)\n",
    "    else:\n",
    "        VCFG1.append(0)  \n",
    "        \n",
    "for i in range(len(a.CodeSum_Station1)):\n",
    "    if re.findall(ls[15],a.CodeSum_Station1[i]):\n",
    "        VCTS1.append(1)\n",
    "    else:\n",
    "        VCTS1.append(0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['BCFG1'] = BCFG1\n",
    "a['BR1'] = BR1\n",
    "a['DZ1'] = DZ1\n",
    "a['FG1'] = FG1 \n",
    "a['FGplus_1'] = FGplus_1 \n",
    "a['FU1'] = FU1\n",
    "a['GR1'] = GR1\n",
    "a['HZ1'] = HZ1\n",
    "a['NO_EVENT1'] = NO_EVENT1 \n",
    "a['RA1'] = RA1\n",
    "a['SN1'] = SN1 \n",
    "a['SQ1'] = SQ1 \n",
    "a['TS1'] = TS1\n",
    "a['TSRA1'] = TSRA1\n",
    "a['VCFG1'] = VCFG1\n",
    "a['VCTS1'] = VCTS1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "BCFG2 = []\n",
    "BR2 = []\n",
    "DZ2 = []\n",
    "FG2 = [] \n",
    "FGplus_2 = [] \n",
    "FU2 = []\n",
    "GR2 = []\n",
    "HZ2 = []\n",
    "NO_EVENT2 = [] \n",
    "RA2 = []\n",
    "SN2 = [] \n",
    "SQ2 = [] \n",
    "TS2 =[]\n",
    "TSRA2 = []\n",
    "VCFG2 = []\n",
    "VCTS2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(a.CodeSum_Station2)):\n",
    "    if re.findall(ls[0],a.CodeSum_Station2[i]):\n",
    "        BCFG2.append(1)\n",
    "    else:\n",
    "        BCFG2.append(0)\n",
    "        \n",
    "for i in range(len(a.CodeSum_Station2)):\n",
    "    if re.findall(ls[1],a.CodeSum_Station2[i]):\n",
    "        BR2.append(1)\n",
    "    else:\n",
    "        BR2.append(0)\n",
    "        \n",
    "for i in range(len(a.CodeSum_Station2)):\n",
    "    if re.findall(ls[2],a.CodeSum_Station2[i]):\n",
    "        DZ2.append(1)\n",
    "    else:\n",
    "        DZ2.append(0)\n",
    "\n",
    "for i in range(len(a.CodeSum_Station2)):\n",
    "    if re.findall(ls[3],a.CodeSum_Station2[i]):\n",
    "        FG2.append(1)\n",
    "    else:\n",
    "        FG2.append(0)\n",
    "\n",
    "for i in range(len(a.CodeSum_Station2)):\n",
    "    if re.findall(ls[4],a.CodeSum_Station2[i]):\n",
    "        FGplus_2.append(1)\n",
    "    else:\n",
    "        FGplus_2.append(0)        \n",
    "\n",
    "for i in range(len(a.CodeSum_Station2)):\n",
    "    if re.findall(ls[5],a.CodeSum_Station2[i]):\n",
    "        FU2.append(1)\n",
    "    else:\n",
    "        FU2.append(0)  \n",
    "        \n",
    "for i in range(len(a.CodeSum_Station2)):\n",
    "    if re.findall(ls[6],a.CodeSum_Station2[i]):\n",
    "        GR2.append(1)\n",
    "    else:\n",
    "        GR2.append(0)  \n",
    "        \n",
    "for i in range(len(a.CodeSum_Station2)):\n",
    "    if re.findall(ls[7],a.CodeSum_Station2[i]):\n",
    "        HZ2.append(1)\n",
    "    else:\n",
    "        HZ2.append(0)  \n",
    "        \n",
    "for i in range(len(a.CodeSum_Station2)):\n",
    "    if re.findall(ls[8],a.CodeSum_Station2[i]):\n",
    "        NO_EVENT2.append(1)\n",
    "    else:\n",
    "        NO_EVENT2.append(0)  \n",
    "        \n",
    "for i in range(len(a.CodeSum_Station2)):\n",
    "    if re.findall(ls[9],a.CodeSum_Station2[i]):\n",
    "        RA2.append(1)\n",
    "    else:\n",
    "        RA2.append(0)  \n",
    "        \n",
    "for i in range(len(a.CodeSum_Station2)):\n",
    "    if re.findall(ls[10],a.CodeSum_Station2[i]):\n",
    "        SN2.append(1)\n",
    "    else:\n",
    "        SN2.append(0)  \n",
    "        \n",
    "for i in range(len(a.CodeSum_Station2)):\n",
    "    if re.findall(ls[11],a.CodeSum_Station2[i]):\n",
    "        SQ2.append(1)\n",
    "    else:\n",
    "        SQ2.append(0)  \n",
    "        \n",
    "for i in range(len(a.CodeSum_Station2)):\n",
    "    if re.findall(ls[12],a.CodeSum_Station2[i]):\n",
    "        TS2.append(1)\n",
    "    else:\n",
    "        TS2.append(0)  \n",
    "        \n",
    "for i in range(len(a.CodeSum_Station2)):\n",
    "    if re.findall(ls[13],a.CodeSum_Station2[i]):\n",
    "        TSRA2.append(1)\n",
    "    else:\n",
    "        TSRA2.append(0)  \n",
    "        \n",
    "for i in range(len(a.CodeSum_Station2)):\n",
    "    if re.findall(ls[14],a.CodeSum_Station2[i]):\n",
    "        VCFG2.append(1)\n",
    "    else:\n",
    "        VCFG2.append(0)  \n",
    "        \n",
    "for i in range(len(a.CodeSum_Station2)):\n",
    "    if re.findall(ls[15],a.CodeSum_Station2[i]):\n",
    "        VCTS2.append(1)\n",
    "    else:\n",
    "        VCTS2.append(0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['BCFG2'] = BCFG1\n",
    "a['BR2'] = BR1\n",
    "a['DZ2'] = DZ1\n",
    "a['FG2'] = FG1 \n",
    "a['FGplus_2'] = FGplus_1 \n",
    "a['FU2'] = FU1\n",
    "a['GR2'] = GR1\n",
    "a['HZ2'] = HZ1\n",
    "a['NO_EVENT2'] = NO_EVENT1 \n",
    "a['RA2'] = RA1\n",
    "a['SN2'] = SN1 \n",
    "a['SQ2'] = SQ1 \n",
    "a['TS2'] = TS1\n",
    "a['TSRA2'] = TSRA1\n",
    "a['VCFG2'] = VCFG1\n",
    "a['VCTS2'] = VCTS1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.to_csv('/Users/jenniferwu/Documents/kaggle-competition1/cleaned_data/weather_var_cleaned.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
